{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'sc.stop()', \"if 'sc' in globals():\\n  sc.stop()\\nelse\\n  print('No hay contexto, lo creamos...')\", \"if 'sc' in globals():\\n  sc.stop()\\nelse:\\n  print('No hay contexto, lo creamos...')\", \"from pyspark import SparkContext\\nif 'sc' in globals():\\n  print('Ya hay contexto')\\n  print(globals())\\nelse:\\n  #sc = SparkContext(master='local[*]', appName='appName')\\n  sc = SparkContext(master='spark://AM-C02ZD04GL414:7077', appName='appName')\", \"from pyspark import SparkContext\\nprint(globals())\\nif 'sc' in globals():\\n  print('Ya hay contexto')\\nelse:\\n  print('No hay contexto, lo creamos')\\n  #sc = SparkContext(master='local[*]', appName='appName')\\n  sc = SparkContext(master='spark://AM-C02ZD04GL414:7077', appName='appName')\"], '_oh': {}, '_dh': [PosixPath('/Users/asaucedov/workspaces/python3/librerias-python/pyspark/pyspark-intro')], 'In': ['', 'sc.stop()', \"if 'sc' in globals():\\n  sc.stop()\\nelse\\n  print('No hay contexto, lo creamos...')\", \"if 'sc' in globals():\\n  sc.stop()\\nelse:\\n  print('No hay contexto, lo creamos...')\", \"from pyspark import SparkContext\\nif 'sc' in globals():\\n  print('Ya hay contexto')\\n  print(globals())\\nelse:\\n  #sc = SparkContext(master='local[*]', appName='appName')\\n  sc = SparkContext(master='spark://AM-C02ZD04GL414:7077', appName='appName')\", \"from pyspark import SparkContext\\nprint(globals())\\nif 'sc' in globals():\\n  print('Ya hay contexto')\\nelse:\\n  print('No hay contexto, lo creamos')\\n  #sc = SparkContext(master='local[*]', appName='appName')\\n  sc = SparkContext(master='spark://AM-C02ZD04GL414:7077', appName='appName')\"], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x10cf4a3c0>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10cf4a6f0>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10cf4a6f0>, 'open': <function open at 0x10bda96c0>, '_': '', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/asaucedov/workspaces/python3/librerias-python/pyspark/pyspark-intro/pyspark-SparkContext.ipynb', '_i': \"from pyspark import SparkContext\\nif 'sc' in globals():\\n  print('Ya hay contexto')\\n  print(globals())\\nelse:\\n  #sc = SparkContext(master='local[*]', appName='appName')\\n  sc = SparkContext(master='spark://AM-C02ZD04GL414:7077', appName='appName')\", '_ii': \"if 'sc' in globals():\\n  sc.stop()\\nelse:\\n  print('No hay contexto, lo creamos...')\", '_iii': \"if 'sc' in globals():\\n  sc.stop()\\nelse\\n  print('No hay contexto, lo creamos...')\", '_i1': 'sc.stop()', '_i2': \"if 'sc' in globals():\\n  sc.stop()\\nelse\\n  print('No hay contexto, lo creamos...')\", '_i3': \"if 'sc' in globals():\\n  sc.stop()\\nelse:\\n  print('No hay contexto, lo creamos...')\", '_i4': \"from pyspark import SparkContext\\nif 'sc' in globals():\\n  print('Ya hay contexto')\\n  print(globals())\\nelse:\\n  #sc = SparkContext(master='local[*]', appName='appName')\\n  sc = SparkContext(master='spark://AM-C02ZD04GL414:7077', appName='appName')\", 'SparkContext': <class 'pyspark.context.SparkContext'>, 'sc': <SparkContext master=spark://AM-C02ZD04GL414:7077 appName=appName>, '_i5': \"from pyspark import SparkContext\\nprint(globals())\\nif 'sc' in globals():\\n  print('Ya hay contexto')\\nelse:\\n  print('No hay contexto, lo creamos')\\n  #sc = SparkContext(master='local[*]', appName='appName')\\n  sc = SparkContext(master='spark://AM-C02ZD04GL414:7077', appName='appName')\"}\n",
      "Ya hay contexto\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "print(globals())\n",
    "if 'sc' in globals():\n",
    "  print('Ya hay contexto')\n",
    "else:\n",
    "  print('No hay contexto, lo creamos')\n",
    "  #sc = SparkContext(master='local[*]', appName='appName')\n",
    "  sc = SparkContext(master='spark://AM-C02ZD04GL414:7077', appName='appName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark://AM-C02ZD04GL414:7077\n",
      "appName\n",
      "app-20240612133201-0003\n",
      "10026\n",
      "driver\n"
     ]
    }
   ],
   "source": [
    "conf = sc.getConf()\n",
    "print(conf.get('spark.master'))\n",
    "print(conf.get('spark.app.name'))\n",
    "print(conf.get('spark.app.id'))\n",
    "print(conf.get('spark.driver.port'))\n",
    "print(conf.get('spark.executor.id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x1136091f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkConf\n",
    "conf = SparkConf()\n",
    "conf.setAppName(\"Test spark\")\n",
    "conf.setMaster(\"spark://AM-C02ZD04GL414:7077\")\n",
    "conf.set(\"spark.blockManager.port\", \"10025\")\n",
    "conf.set(\"spark.driver.blockManager.port\", \"10026\")\n",
    "conf.set(\"spark.driver.port\", \"58589\")\n",
    "conf.set(\"spark.cores.max\", \"12\") \n",
    "conf.set(\"spark.executor.memory\", \"2g\")\n",
    "conf.set(\"spark.driver.host\", \"192.168.1.134\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spark://AM-C02ZD04GL414:7077'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/12 13:32:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240612133234-0004/0 is now RUNNING\n",
      "24/06/12 13:32:38 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.134:50011) with ID 0,  ResourceProfileId 0\n",
      "24/06/12 13:32:38 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.134:10025 with 1048.8 MiB RAM, BlockManagerId(0, 192.168.1.134, 10025, None)\n"
     ]
    }
   ],
   "source": [
    "# creo SparkContext con un objeto de configuración\n",
    "sc.stop()\n",
    "sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel('INFO')\n",
    "sc.master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/12 13:32:45 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "24/06/12 13:32:45 INFO SharedState: Warehouse path is 'file:/Users/asaucedov/workspaces/python3/librerias-python/pyspark/spark-warehouse'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.134:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://AM-C02ZD04GL414:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Test spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1126f3530>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "  .appName('Test spark NUEVA') \\\n",
    "  .config('spark.driver.host', '192.168.1.134') \\\n",
    "  .config('spark.driver.port', '10026') \\\n",
    "  .getOrCreate()\n",
    "SparkSession.active()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = spark.createDataFrame([{\"age\": 150, \"name\": \"Perico Pérez\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/12 13:33:03 INFO SparkContext: SparkContext is stopping with exitCode 0.\n",
      "24/06/12 13:33:03 INFO SparkUI: Stopped Spark web UI at http://192.168.1.134:4040\n",
      "24/06/12 13:33:03 INFO StandaloneSchedulerBackend: Shutting down all executors\n",
      "24/06/12 13:33:03 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down\n",
      "24/06/12 13:33:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "24/06/12 13:33:03 INFO MemoryStore: MemoryStore cleared\n",
      "24/06/12 13:33:03 INFO BlockManager: BlockManager stopped\n",
      "24/06/12 13:33:03 INFO BlockManagerMaster: BlockManagerMaster stopped\n",
      "24/06/12 13:33:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "24/06/12 13:33:03 INFO SparkContext: Successfully stopped SparkContext\n"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msc\u001b[49m\u001b[38;5;241m.\u001b[39mstop()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
